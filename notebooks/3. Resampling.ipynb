{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "The number of shoes sold by an e-commerce company during the first three months(12 weeks) of the year were:\n",
    "<br>\n",
    "23 21 19 24 35 17 18 24 33 27 21 23\n",
    "\n",
    "Meanwhile, the company developed some dynamic price optimization algorithms and the sales for the next 12 weeks were:\n",
    "<br>\n",
    "31 28 19 24 32 27 16 41 23 32 29 33\n",
    "\n",
    "Did the dynamic price optimization algorithm deliver superior results? Can it be trusted?\n",
    "\n",
    "### Solution\n",
    "\n",
    "Before we get onto different approaches, let's quickly get a feel for the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data\n",
    "before_opt = np.array([23, 21, 19, 24, 35, 17, 18, 24, 33, 27, 21, 23])\n",
    "after_opt = np.array([31, 28, 19, 24, 32, 27, 16, 41, 23, 32, 29, 33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "before_opt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "after_opt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observed_difference = after_opt.mean() - before_opt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Difference between the means is:\", observed_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, the sales after optimization is more than the sales before optimization. But is the difference legit? Could it be due to chance?\n",
    "\n",
    "**Classical Method** : We could cover this method later on. This entails doing a *t-test* \n",
    "\n",
    "**Hacker's Method** : Let's see if we can provide a hacker's perspective to this problem, similar to what we did in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 1: Create the dataset. Let's give Label 0 to before_opt and Label 1 to after_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Learn about the following three functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?np.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?np.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?np.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shoe_sales = np.array([np.append(np.zeros(before_opt.shape[0]), np.ones(after_opt.shape[0])),\n",
    "np.append(before_opt, after_opt)], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Shape:\", shoe_sales.shape\n",
    "print \"Data:\", \"\\n\", shoe_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shoe_sales = shoe_sales.T\n",
    "print \"Shape:\",shoe_sales.shape\n",
    "print \"Data:\", \"\\n\", shoe_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the approach we are going to take\n",
    "#We are going to randomly shuffle the labels. Then compute the mean between the two groups. \n",
    "#Find the % of times when the difference between the means computed is greater than what we observed above\n",
    "#If the % of times is less than 5%, we would make the call that the improvements are real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(shoe_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shoe_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_label = np.random.randint(0,2,shoe_sales.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_data = np.array([experiment_label, shoe_sales[:,1]])\n",
    "experiment_data = experiment_data.T\n",
    "print experiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_diff_mean =  experiment_data[experiment_data[:,0]==1].mean() \\\n",
    "                        - experiment_data[experiment_data[:,0]==0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_diff_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Like the previous notebook, let's repeat this experiment 100 and then 100000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_experiment(number_of_times):\n",
    "    experiment_diff_mean = np.empty([number_of_times,1])\n",
    "    for times in np.arange(number_of_times):\n",
    "        experiment_label = np.random.randint(0,2,shoe_sales.shape[0])\n",
    "        experiment_data = np.array([experiment_label, shoe_sales[:,1]]).T\n",
    "        experiment_diff_mean[times] =  experiment_data[experiment_data[:,0]==1].mean() \\\n",
    "                        - experiment_data[experiment_data[:,0]==0].mean()\n",
    "    return experiment_diff_mean    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_diff_mean = shuffle_experiment(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_diff_mean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(experiment_diff_mean, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding % of times difference of means is greater than observed\n",
    "print \"Data: Difference in mean greater than observed:\", \\\n",
    "        experiment_diff_mean[experiment_diff_mean>=observed_difference]\n",
    "\n",
    "print \"Number of times diff in mean greater than observed:\", \\\n",
    "            experiment_diff_mean[experiment_diff_mean>=observed_difference].shape[0]\n",
    "print \"% of times diff in mean greater than observed:\", \\\n",
    "        experiment_diff_mean[experiment_diff_mean>=observed_difference].shape[0]/float(experiment_diff_mean.shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Repeat the above for 100,000 runs and report the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the result by chance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the justification for shuffling the labels? \n",
    "\n",
    ">Thought process is this: If price optimization had no real effect, then, the sales before optimization would often give more sales than sales after optimization. By shuffling, we are simulating the situation where that happens -  sales before optimization is greater than sales after optimization. If many such trials provide improvements, then, the price optimization has no effect. In statistical terms, *the observed difference could have occurred by chance*. \n",
    "\n",
    "Now, to show that the same difference in mean might lead to a different conclusion, let's try the same experiment with a different dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "before_opt = np.array([230, 210, 190, 240, 350, 170, 180, 240, 330, 270, 210, 230])\n",
    "after_opt = np.array([310, 180, 190, 240, 220, 240, 160, 410, 130, 320, 290, 210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Mean sales before price optimization:\", np.mean(before_opt)\n",
    "print \"Mean sales after price optimization:\", np.mean(after_opt)\n",
    "print \"Difference in mean sales:\", np.mean(after_opt) - np.mean(before_opt) #Same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shoe_sales = np.array([np.append(np.zeros(before_opt.shape[0]), np.ones(after_opt.shape[0])),\n",
    "np.append(before_opt, after_opt)], dtype=int)\n",
    "shoe_sales = shoe_sales.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_diff_mean = shuffle_experiment(100000)\n",
    "sns.distplot(experiment_diff_mean, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding % of times difference of means is greater than observed\n",
    "print \"Number of times diff in mean greater than observed:\", \\\n",
    "            experiment_diff_mean[experiment_diff_mean>=observed_difference].shape[0]\n",
    "print \"% of times diff in mean greater than observed:\", \\\n",
    "        experiment_diff_mean[experiment_diff_mean>=observed_difference].shape[0]/float(experiment_diff_mean.shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did the conclusion change now? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect Size\n",
    "\n",
    "> **Because you can't argue with all the fools in the world. It's easier to let them have their way, then trick them when they're not paying attention**  - Christopher Paolini\n",
    "\n",
    "In the first case, how much did the price optimization increase the sales on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "before_opt = np.array([23, 21, 19, 24, 35, 17, 18, 24, 33, 27, 21, 23])\n",
    "after_opt = np.array([31, 28, 19, 24, 32, 27, 16, 41, 23, 32, 29, 33])\n",
    "\n",
    "print \"The % increase of sales in the first case:\", \\\n",
    "(np.mean(after_opt) - np.mean(before_opt))/np.mean(before_opt)*100,\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "before_opt = np.array([230, 210, 190, 240, 350, 170, 180, 240, 330, 270, 210, 230])\n",
    "after_opt = np.array([310, 180, 190, 240, 220, 240, 160, 410, 130, 320, 290, 210])\n",
    "\n",
    "print \"The % increase of sales in the second case:\", \\\n",
    "(np.mean(after_opt) - np.mean(before_opt))/np.mean(before_opt)*100,\"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Would business feel comfortable spending millions of dollars if the increase is going to be just 1.75%. Does it make sense? Maybe yes - if margins are thin and any increase is considered good. But if the returns from the price optimization module does not let the company break even, it makes no sense to take that path.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Someone tells you the result is statistically significant. The first question you should ask?\n",
    "\n",
    "# How large is the effect?\n",
    "\n",
    "To answer such a question, we will make use of the concept **confidence interval**\n",
    "\n",
    "In plain english, *confidence interval* is the range of values the measurement metric is going to take. \n",
    "\n",
    "An example would be: 90% of the times, the increase in average sales (before and after price optimization) would be within the bucket `3.4 and 6.7` (These numbers are illustrative. We will derive those numbers below)\n",
    "\n",
    "What is the *hacker's way* of doing it? We will do the following steps:\n",
    "\n",
    "1. From actual sales data, we sample the data with repetition (separately for before and after) - sample size will be the same as the original\n",
    "2. Find the differences between the mean of the two samples.\n",
    "3. Repeat steps 1 and 2 , say 100,000 times.\n",
    "4. Sort the differences. For getting 90% interval, take the 5% and 95% number. That range gives you the 90% confidence interval on the mean.\n",
    "5. This process of generating the samples is called **bootstrapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data\n",
    "before_opt = np.array([23, 21, 19, 24, 35, 17, 18, 24, 33, 27, 21, 23])\n",
    "after_opt = np.array([31, 28, 19, 24, 32, 27, 16, 41, 23, 32, 29, 33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generate a uniform random sample\n",
    "random_before_opt = np.random.choice(before_opt, size=before_opt.size, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Actual sample before optimization:\", before_opt\n",
    "print \"Bootstrapped sample before optimization: \", random_before_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Mean for actual sample:\", np.mean(before_opt)\n",
    "print \"Mean for bootstrapped sample:\", np.mean(random_before_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_after_opt = np.random.choice(after_opt, size=after_opt.size, replace=True)\n",
    "print \"Actual sample after optimization:\", after_opt\n",
    "print \"Bootstrapped sample after optimization: \", random_after_opt\n",
    "print \"Mean for actual sample:\", np.mean(after_opt)\n",
    "print \"Mean for bootstrapped sample:\", np.mean(random_after_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Difference in means of actual samples:\", np.mean(after_opt) - np.mean(before_opt)\n",
    "print \"Difference in means of bootstrapped samples:\", np.mean(random_after_opt) - np.mean(random_before_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Like always, we will repeat this experiment 100,000 times. \n",
    "\n",
    "def bootstrap_experiment(number_of_times):\n",
    "    mean_difference = np.empty([number_of_times,1])\n",
    "    for times in np.arange(number_of_times):\n",
    "        random_before_opt = np.random.choice(before_opt, size=before_opt.size, replace=True)\n",
    "        random_after_opt = np.random.choice(after_opt, size=after_opt.size, replace=True)\n",
    "        mean_difference[times] = np.mean(random_after_opt) - np.mean(random_before_opt)\n",
    "    return mean_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_difference = bootstrap_experiment(100000)\n",
    "sns.distplot(mean_difference, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_difference = np.sort(mean_difference, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_difference #Sorted difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.percentile(mean_difference, [5,95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reiterating what this means: 90% of the times, the mean difference is between the limits as shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Find the 95% percentile for confidence intevals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where do we go from here? \n",
    "\n",
    "First of all there are two points to be made.\n",
    "\n",
    "1. Whey do we need signficance testing if confidence intervals can provide us more information?\n",
    "2. How does it relate to the traditional statistical procedure of finding confidence intervals\n",
    "\n",
    "For the first one:\n",
    "\n",
    "What if sales in the first month after price changes was 80 and the month before price changes was 40. The difference is 40. And confidence interval,as explained above, using replacements, would always generate 40. But if we do the significance testing, as detailed above - where the labels are shuffled, the prices are equally likely to occur in both the groups. And so, significance testing would answer that there was no difference. But don't we all know that the data is **too small** to make meaningful inferences?\n",
    "\n",
    "For the second one:\n",
    "\n",
    "Traditional statistics derivation assumes normal distribution. But what if the underlying distribution isn't normal? Also, people relate to resampling much better :-) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
